{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb37f0ef-da86-4270-821a-78f299dabb17",
   "metadata": {},
   "source": [
    "This notebook provides a short sample on how to evaluate your trained model. We will continue from our previous notebook `03_` which has trained a working model. \n",
    "\n",
    "The complete evaluation script can be found in the root directory of the repository `eval_iter.py` or `eval_ensemble.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9936fab-6071-442f-9f83-78ea05b743ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa03359-4eb3-4078-9577-bc17e7861ddf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch import loggers as pl_loggers\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "pl.seed_everything(42)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid', {'axes.grid' : False})\n",
    "sns.set_theme(context='paper')\n",
    "\n",
    "# Adjusting global plotting parameters\n",
    "plt.rcParams['font.size'] = 40        # Adjusts the main font size\n",
    "plt.rcParams['axes.labelsize'] = 32   # Font size of x and y labels\n",
    "plt.rcParams['xtick.labelsize'] = 32  # Font size of numbers on x-axis\n",
    "plt.rcParams['ytick.labelsize'] = 32  # Font size of numbers on y-axis\n",
    "plt.rcParams['legend.fontsize'] = 32  # Font size of legend\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from chaosbench import dataset, config, utils, criterion\n",
    "from chaosbench.models import model, mlp, cnn, ae\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23552e0-7f24-4b4a-ab64-5e0454d95a3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Handle for evaluation\n",
    "metrics = ['rmse', 'acc', 'bias', 'ssim', 'sdiv']\n",
    "headline_vars = dict({'t-850': 'K', 'z-500': 'gpm', 'q-700': r'$10^{-3}kg kg^{-1}$'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fa0bce-38ef-468e-bf5f-15ce089ee3df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Handle consistent limit for plotting\n",
    "y_lim = {\n",
    "    'rmse': {'t-850': {'min': 0.5, 'max': 6}, 'z-500': {'min': 0, 'max': 150}, 'q-700': {'min': 0.0005, 'max': 0.0030}},\n",
    "    'acc': {'t-850': {'min': -0.3, 'max': 1}, 'z-500': {'min': -0.3, 'max': 1}, 'q-700': {'min': -0.3, 'max': 1}},\n",
    "    'bias': {'t-850': {'min': -2.0, 'max': 1}, 'z-500': {'min': -40, 'max': 40}, 'q-700': {'min': -0.0005, 'max': 0.0005}},\n",
    "    'ssim': {'t-850': {'min': 0.6, 'max': 1}, 'z-500': {'min': 0.6, 'max': 1}, 'q-700': {'min': 0.3, 'max': 1}}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc5fd05-1b28-4c65-bf84-1e72bf2b865f",
   "metadata": {},
   "source": [
    "## Data-driven models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8760be18-c327-4c05-91e9-e187579dfd69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluate metrics across data-driven models\n",
    "linecolors = ['black', '#1f77b4', '#ff7f0e', '#2ca02c', '#C44E52']\n",
    "model_names = ['climatology', 'panguweather', 'graphcast', 'fourcastnetv2']\n",
    "labels = ['Climatology', 'PW', 'GC', 'FCN2']\n",
    "\n",
    "# Iterate over each metric\n",
    "for metric_idx, metric in enumerate(metrics):\n",
    "    f, axes = plt.subplots(1, len(headline_vars), figsize=(10*len(headline_vars), 10))\n",
    "\n",
    "    for headline_idx, (headline_var, headline_unit) in enumerate(headline_vars.items()):\n",
    "        ax = axes[headline_idx] if len(headline_vars) > 1 else axes\n",
    "        data_to_plot = []\n",
    "\n",
    "        # Plot\n",
    "        for model_idx, model_name in enumerate(model_names):\n",
    "            df = pd.read_csv(Path(f'../logs/{model_name}/eval/{metric}_{model_name}.csv'))\n",
    "            \n",
    "            try:\n",
    "                y = df[[headline_var]].to_numpy().squeeze()\n",
    "\n",
    "                # Calculate the average of all timesteps if the metric requires a bar plot\n",
    "                if metric in ['sres', 'sdiv']:\n",
    "                    average_y = np.nanmean(y)  # Use nanmean to handle NaN values safely\n",
    "                    data_to_plot.append({'Model': labels[model_idx], 'Average': average_y})\n",
    "                    bar = sns.barplot(\n",
    "                        x='Model',\n",
    "                        y='Average',\n",
    "                        data=pd.DataFrame(data_to_plot),\n",
    "                        ax=ax,\n",
    "                        palette=linecolors\n",
    "                    )\n",
    "                    ax.set_ylim(0, 0.5)\n",
    "                    bar.set_xticklabels(bar.get_xticklabels(), rotation=30) \n",
    "                \n",
    "                # Otherwise plot each model's line\n",
    "                else:\n",
    "                    if y.mean() != 0.0:  # Only plot if the mean is not zero\n",
    "                        \n",
    "                        sns.lineplot(\n",
    "                            x=np.arange(1, df.shape[0]+1),\n",
    "                            y=y, \n",
    "                            label=labels[model_idx],\n",
    "                            linewidth=5,\n",
    "                            color=linecolors[model_idx],\n",
    "                            ax=ax\n",
    "                        )\n",
    "                    ax.set_ylim(y_lim[metric][headline_var]['min'], y_lim[metric][headline_var]['max'])\n",
    "                \n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        # Customize labels and titles based on the metric\n",
    "        x_label = '' if metric in ['sres', 'sdiv'] else 'Number of days ahead' \n",
    "        y_label = f'{metric.upper()}' if metric in ['acc', 'ssim', 'sres', 'sdiv'] else f'{metric.upper()} [{headline_unit}]'\n",
    "        ax.set_xlabel(x_label)\n",
    "        ax.set_ylabel(y_label)\n",
    "        ax.set_title(f'{headline_var}', fontsize=40)\n",
    "\n",
    "        # Setting the formatter for scientific notation\n",
    "        formatter = mticker.ScalarFormatter(useMathText=True)\n",
    "        formatter.set_scientific(True)\n",
    "        formatter.set_powerlimits((-2,2))\n",
    "        ax.yaxis.set_major_formatter(formatter)\n",
    "\n",
    "        # Show legend if it's not a bar plot for sres or sdiv\n",
    "        if metric not in ['sres', 'sdiv']:\n",
    "            ax.legend()\n",
    "\n",
    "    # Adjust layout and show plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    f.savefig(f'../docs/sota_{metric}.pdf', dpi=200, bbox_inches='tight');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc41038a-d2d3-45e3-9d7f-864c9d6befa1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Physics-based models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a160513a-98d2-4e7c-9ab7-b51f976309c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluate metrics across physics-based models maintained by different centers\n",
    "# Case 1a: control forecasts\n",
    "metrics = ['rmse', 'acc', 'bias', 'ssim', 'sdiv']\n",
    "linecolors = {'climatology': 'black', 'ecmwf': '#1f77b4', 'cma': '#ff7f0e', 'ukmo': '#2ca02c', 'ncep': '#C44E52'}\n",
    "model_names = {'climatology': 'Climatology', 'ecmwf': 'ECMWF', 'cma': 'CMA', 'ukmo': 'UKMO', 'ncep': 'NCEP'}\n",
    "\n",
    "# Iterate over each metric\n",
    "for metric_idx, metric in enumerate(metrics):\n",
    "    f, axes = plt.subplots(1, len(headline_vars), figsize=(10 * len(headline_vars), 10))\n",
    "\n",
    "    for headline_idx, (headline_var, headline_unit) in enumerate(headline_vars.items()):\n",
    "        ax = axes[headline_idx] if len(headline_vars) > 1 else axes\n",
    "        data_to_plot = []\n",
    "\n",
    "        # Plot\n",
    "        for model_name, model_label in model_names.items():\n",
    "            df = pd.read_csv(Path(f'../logs/{model_name}/eval/{metric}_{model_name}.csv'))\n",
    "            y = df[headline_var].to_numpy()\n",
    "\n",
    "            if metric in ['sres', 'sdiv']:\n",
    "                y = np.nanmean(y)\n",
    "                data_to_plot.append({'Model': model_label, 'Average': y})\n",
    "            \n",
    "            else:\n",
    "                if np.nanmean(df) != 0.0:\n",
    "                    sns.lineplot(\n",
    "                        x=np.arange(1, df.shape[0]+1),\n",
    "                        y=y,\n",
    "                        label=f'{model_names[model_name]}',\n",
    "                        linewidth=5,\n",
    "                        linestyle='-',\n",
    "                        color=linecolors[model_name],\n",
    "                        ax=ax\n",
    "                    )\n",
    "                \n",
    "                ax.set_ylim(y_lim[metric][headline_var]['min'], y_lim[metric][headline_var]['max'])\n",
    "                \n",
    "\n",
    "        # Plot bar for metrics that require it\n",
    "        if metric in ['sres', 'sdiv']:\n",
    "            bar = sns.barplot(\n",
    "                x='Model',\n",
    "                y='Average',\n",
    "                data=pd.DataFrame(data_to_plot),\n",
    "                ax=ax,\n",
    "                palette=[linecolors[name.split()[0].lower()] for name in model_names.values()]\n",
    "            )\n",
    "            \n",
    "            ax.set_ylim(0, 0.5)\n",
    "            bar.set_xticklabels(bar.get_xticklabels(), rotation=30)\n",
    "\n",
    "        # Customize labels and titles based on the metric\n",
    "        x_label = '' if metric in ['sres', 'sdiv'] else 'Number of days ahead'\n",
    "        y_label = f'{metric.upper()}' if metric in ['acc', 'ssim', 'sres', 'sdiv'] else f'{metric.upper()} [{headline_unit}]'\n",
    "        ax.set_xlabel(x_label)\n",
    "        ax.set_ylabel(y_label)\n",
    "        ax.set_title(f'{headline_var}', fontsize=40)\n",
    "\n",
    "        # Setting the formatter for scientific notation\n",
    "        formatter = mticker.ScalarFormatter(useMathText=True)\n",
    "        formatter.set_scientific(True)\n",
    "        formatter.set_powerlimits((-2, 2))\n",
    "        ax.yaxis.set_major_formatter(formatter)\n",
    "\n",
    "        # Show legend if it's not a bar plot for sres or sdiv\n",
    "        if metric not in ['sres', 'sdiv']:\n",
    "            ax.legend()\n",
    "\n",
    "    # Adjust layout and show plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    f.savefig(f'../docs/center_{metric}.pdf', dpi=200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b5e911-6c27-4ddb-8b8c-e4732e1b05db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluate metrics across physics-based models maintained by different centers\n",
    "# Case 1b: ensemble\n",
    "metrics = ['rmse', 'acc', 'bias', 'ssim', 'sdiv']\n",
    "linecolors = {'climatology': 'black', 'ecmwf': '#1f77b4', 'cma': '#ff7f0e', 'ukmo': '#2ca02c', 'ncep': '#C44E52'}\n",
    "model_names = {'climatology': 'Climatology', 'ecmwf': 'ECMWF (n=50)', 'cma': 'CMA (n=3)', 'ukmo': 'UKMO (n=3)', 'ncep': 'NCEP (n=15)'}\n",
    "\n",
    "# Iterate over each metric\n",
    "for metric_idx, metric in enumerate(metrics):\n",
    "    f, axes = plt.subplots(1, len(headline_vars), figsize=(10 * len(headline_vars), 10))\n",
    "\n",
    "    for headline_idx, (headline_var, headline_unit) in enumerate(headline_vars.items()):\n",
    "        ax = axes[headline_idx] if len(headline_vars) > 1 else axes\n",
    "        data_to_plot = []\n",
    "\n",
    "        # Plot\n",
    "        for model_name, model_label in model_names.items():\n",
    "            if model_name == 'climatology':\n",
    "                df = pd.read_csv(Path(f'../logs/{model_name}/eval/{metric}_{model_name}.csv'))\n",
    "            else:\n",
    "                df = pd.read_csv(Path(f'../logs/{model_name}_ensemble/eval/{metric}_{model_name}.csv'))\n",
    "            \n",
    "            y = df[headline_var].to_numpy()\n",
    "\n",
    "            if metric in ['sres', 'sdiv']:\n",
    "                y = np.nanmean(y)\n",
    "                data_to_plot.append({'Model': model_label, 'Average': y})\n",
    "            else:\n",
    "                if np.nanmean(df) != 0.0:\n",
    "                    sns.lineplot(\n",
    "                        x=np.arange(1, df.shape[0]+1),\n",
    "                        y=y,\n",
    "                        label=f'{model_names[model_name]}',\n",
    "                        linewidth=5,\n",
    "                        linestyle='-',\n",
    "                        color=linecolors[model_name],\n",
    "                        ax=ax\n",
    "                    )\n",
    "                \n",
    "\n",
    "        # Plot bar for metrics that require it\n",
    "        if metric in ['sres', 'sdiv']:\n",
    "            bar = sns.barplot(\n",
    "                x='Model',\n",
    "                y='Average',\n",
    "                data=pd.DataFrame(data_to_plot),\n",
    "                ax=ax,\n",
    "                palette=[linecolors[name.split()[0].lower()] for name in model_names.values()]\n",
    "            )\n",
    "            bar.set_xticklabels(bar.get_xticklabels(), rotation=30)\n",
    "\n",
    "        # Customize labels and titles based on the metric\n",
    "        x_label = '' if metric in ['sres', 'sdiv'] else 'Number of days ahead'\n",
    "        y_label = f'{metric.upper()}' if metric in ['acc', 'ssim', 'sres', 'sdiv'] else f'{metric.upper()} [{headline_unit}]'\n",
    "        ax.set_xlabel(x_label)\n",
    "        ax.set_ylabel(y_label)\n",
    "        ax.set_title(f'{headline_var}', fontsize=40)\n",
    "\n",
    "        # Setting the formatter for scientific notation\n",
    "        formatter = mticker.ScalarFormatter(useMathText=True)\n",
    "        formatter.set_scientific(True)\n",
    "        formatter.set_powerlimits((-2, 2))\n",
    "        ax.yaxis.set_major_formatter(formatter)\n",
    "\n",
    "        # Show legend if it's not a bar plot for sres or sdiv\n",
    "        if metric not in ['sres', 'sdiv']:\n",
    "            ax.legend()\n",
    "\n",
    "    # Adjust layout and show plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    f.savefig(f'../docs/center_ens_{metric}.pdf', dpi=200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8317f7-52c0-4f53-8c01-b29d899c6eb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluate metrics across physics-based models maintained by different centers\n",
    "# Case 1c: ensemble/deterministic ratio\n",
    "metrics = ['rmse', 'acc', 'bias', 'ssim', 'sdiv']\n",
    "linecolors = {'ecmwf': '#1f77b4', 'cma': '#ff7f0e', 'ukmo': '#2ca02c', 'ncep': '#C44E52'}\n",
    "model_names = {'ecmwf': 'ECMWF (n=50)', 'cma': 'CMA (n=3)', 'ukmo': 'UKMO (n=3)', 'ncep': 'NCEP (n=15)'}\n",
    "\n",
    "# Iterate over each metric\n",
    "for metric_idx, metric in enumerate(metrics):\n",
    "    f, axes = plt.subplots(1, len(headline_vars), figsize=(10 * len(headline_vars), 10))\n",
    "\n",
    "    for headline_idx, (headline_var, headline_unit) in enumerate(headline_vars.items()):\n",
    "        ax = axes[headline_idx] if len(headline_vars) > 1 else axes\n",
    "        data_to_plot = []\n",
    "\n",
    "        # Plot the ratio between control and ensemble models\n",
    "        for model_name, model_label in model_names.items():\n",
    "            control_df = pd.read_csv(Path(f'../logs/{model_name}/eval/{metric}_{model_name}.csv'))\n",
    "            ensemble_df = pd.read_csv(Path(f'../logs/{model_name}_ensemble/eval/{metric}_{model_name}.csv'))\n",
    "            \n",
    "            control_y = control_df[headline_var].to_numpy()\n",
    "            ensemble_y = ensemble_df[headline_var].to_numpy()\n",
    "\n",
    "            if len(control_y) != len(ensemble_y):\n",
    "                raise ValueError(f\"Length mismatch between control and ensemble for {model_name}\")\n",
    "\n",
    "            # Calculate the ratio\n",
    "            ratio_y = ensemble_y / control_y\n",
    "\n",
    "            if metric in ['sres', 'sdiv']:\n",
    "                average_ratio_y = np.nanmean(ratio_y)\n",
    "                data_to_plot.append({'Model': model_label, 'Average': average_ratio_y})\n",
    "            else:\n",
    "                if np.nanmean(ratio_y) != 0.0:\n",
    "                    sns.lineplot(\n",
    "                        x=np.arange(1, len(ratio_y) + 1),\n",
    "                        y=ratio_y,\n",
    "                        label=f'{model_names[model_name]}',\n",
    "                        linewidth=5,\n",
    "                        linestyle='-',\n",
    "                        color=linecolors[model_name],\n",
    "                        ax=ax\n",
    "                    )\n",
    "                    \n",
    "\n",
    "        # Plot bar for metrics that require it\n",
    "        if metric in ['sres', 'sdiv']:\n",
    "            bar = sns.barplot(\n",
    "                x='Model',\n",
    "                y='Average',\n",
    "                data=pd.DataFrame(data_to_plot),\n",
    "                ax=ax,\n",
    "                palette=[linecolors[name.split()[0].lower()] for name in model_names.values()]\n",
    "            )\n",
    "            bar.set_xticklabels(bar.get_xticklabels(), rotation=30)\n",
    "\n",
    "        # Customize labels and titles based on the metric\n",
    "        x_label = '' if metric in ['sres', 'sdiv'] else 'Number of days ahead'\n",
    "        y_label = f'{metric.upper()} [ens/det]'\n",
    "        ax.set_xlabel(x_label)\n",
    "        ax.set_ylabel(y_label)\n",
    "        ax.set_title(f'{headline_var}', fontsize=40)\n",
    "\n",
    "        # Setting the formatter for scientific notation\n",
    "        formatter = mticker.ScalarFormatter(useMathText=True)\n",
    "        formatter.set_scientific(True)\n",
    "        formatter.set_powerlimits((-2, 2))\n",
    "        ax.yaxis.set_major_formatter(formatter)\n",
    "\n",
    "        # Show legend if it's not a bar plot for sres or sdiv\n",
    "        if metric not in ['sres', 'sdiv']:\n",
    "            ax.legend()\n",
    "\n",
    "    # Adjust layout and show plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    f.savefig(f'../docs/center_ratio_{metric}.pdf', dpi=200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424052c6-1a74-4087-933f-421f03be9c36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluate metrics across physics-based models maintained by different centers\n",
    "# Case 2: probabilistic metrics\n",
    "metrics = ['crps', 'crpss', 'spread', 'ssr']\n",
    "linecolors = {'ecmwf': '#1f77b4', 'cma': '#ff7f0e', 'ukmo': '#2ca02c', 'ncep': '#C44E52'}\n",
    "model_names = {'ecmwf': 'ECMWF (n=50)', 'cma': 'CMA (n=3)', 'ukmo': 'UKMO (n=3)', 'ncep': 'NCEP (n=15)'}\n",
    "\n",
    "for metric_idx, metric in enumerate(metrics):\n",
    "    f, axes = plt.subplots(1, len(headline_vars), figsize=(10*len(headline_vars), 10))\n",
    "\n",
    "    for headline_idx, (headline_var, headline_unit) in enumerate(headline_vars.items()):\n",
    "        ax = axes[headline_idx] if len(headline_vars) > 1 else axes\n",
    "        data_to_plot = []\n",
    "\n",
    "        # Collect and plot data for this headline variable\n",
    "        for model_name, model_label in model_names.items():\n",
    "            \n",
    "            df = pd.read_csv(Path(f'../logs/{model_name}_ensemble/eval/{metric}_{model_name}.csv'))\n",
    "            y = df[[headline_var]].to_numpy().squeeze()\n",
    "\n",
    "            if y.mean() != 0.0:  # Only plot if the mean is not zero\n",
    "                    \n",
    "                sns.lineplot(\n",
    "                    x=np.arange(1, df.shape[0]+1),\n",
    "                    y=y, \n",
    "                    label=model_label,\n",
    "                    linewidth=5,\n",
    "                    color=linecolors[model_name],\n",
    "                    ax=ax\n",
    "                )\n",
    "            \n",
    "\n",
    "        # Customize labels and titles based on the metric\n",
    "        x_label = '' if metric in ['sres', 'sdiv'] else 'Number of days ahead' \n",
    "        y_label = f'{metric.upper()}' if metric in ['crpss', 'ssr'] else f'{metric.upper()} [{headline_unit}]'\n",
    "        ax.set_xlabel(x_label)\n",
    "        ax.set_ylabel(y_label)\n",
    "        ax.set_title(f'{headline_var}', fontsize=40)\n",
    "\n",
    "        # Setting the formatter for scientific notation\n",
    "        formatter = mticker.ScalarFormatter(useMathText=True)\n",
    "        formatter.set_scientific(True)\n",
    "        formatter.set_powerlimits((-2,2))\n",
    "        ax.yaxis.set_major_formatter(formatter)\n",
    "        ax.legend()\n",
    "\n",
    "    # Adjust layout and show plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    f.savefig(f'../docs/center_probs_{metric}.pdf', dpi=200, bbox_inches='tight');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbfb8b2-08b9-44b9-ba23-22fa51004c03",
   "metadata": {},
   "source": [
    "### Ablation 1: Autoregressive vs direct training..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784136ec-b2bc-4074-a394-74c2c9e55823",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluate metrics across direct vs autoregressive approaches\n",
    "metrics = ['rmse', 'bias', 'ssim', 'sdiv']\n",
    "linecolors = {'climatology': 'black', 'climax/direct_1': '#1f77b4', 'panguweather': '#ff7f0e', 'graphcast': '#2ca02c', 'fourcastnetv2': '#C44E52'}\n",
    "model_names = {'climatology': 'Climatology', 'climax/direct_1': 'ClimaX/Direct', 'panguweather': 'PW/Autoreg', 'graphcast': 'GC/Autoreg', 'fourcastnetv2': 'FCN2/Autoreg'}\n",
    "\n",
    "for metric_idx, metric in enumerate(metrics):\n",
    "    f, axes = plt.subplots(1, len(headline_vars), figsize=(10*len(headline_vars), 10))\n",
    "\n",
    "    for headline_idx, (headline_var, headline_unit) in enumerate(headline_vars.items()):\n",
    "        ax = axes[headline_idx] if len(headline_vars) > 1 else axes\n",
    "        data_to_plot = []\n",
    "\n",
    "        # Collect and plot data for this headline variable\n",
    "        for model_name, model_label in model_names.items():\n",
    "            if 'climax' in model_name or 's2s' in model_name:\n",
    "                model_basename, model_task = model_name.split('/')\n",
    "                df = pd.read_csv(Path(f'../logs/{model_basename}/eval/{model_task}/{metric}_{model_basename}.csv'))\n",
    "\n",
    "            else:\n",
    "                df = pd.read_csv(Path(f'../logs/{model_name}/eval/{metric}_{model_name}.csv'))\n",
    "            \n",
    "            try:\n",
    "                y = df[[headline_var]].to_numpy().squeeze()\n",
    "\n",
    "                # Calculate the average of all timesteps if the metric requires a bar plot\n",
    "                if metric in ['sres', 'sdiv']:\n",
    "                    average_y = np.nanmean(y)  # Use nanmean to handle NaN values safely\n",
    "                    data_to_plot.append({'Model': model_name, 'Average': average_y})\n",
    "                    bar = sns.barplot(\n",
    "                        x='Model',\n",
    "                        y='Average',\n",
    "                        data=pd.DataFrame(data_to_plot),\n",
    "                        label=model_label,\n",
    "                        ax=ax,\n",
    "                        palette=linecolors\n",
    "                    )\n",
    "                    bar.set_xticklabels(bar.get_xticklabels(), rotation=15) \n",
    "                \n",
    "                # Otherwise plot each model's line\n",
    "                else:\n",
    "                    if y.mean() != 0.0:  # Only plot if the mean is not zero\n",
    "                        sns.lineplot(\n",
    "                            x=np.arange(1, df.shape[0]+1),\n",
    "                            y=y, \n",
    "                            label=model_label,\n",
    "                            linewidth=5,\n",
    "                            color=linecolors[model_name],\n",
    "                            ax=ax\n",
    "                        )\n",
    "                \n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        # Customize labels and titles based on the metric\n",
    "        x_label = '' if metric in ['sres', 'sdiv'] else 'Number of days ahead' \n",
    "        y_label = f'{metric.upper()}' if metric in ['acc', 'ssim', 'sres', 'sdiv'] else f'{metric.upper()} [{headline_unit}]'\n",
    "        ax.set_xlabel(x_label)\n",
    "        ax.set_ylabel(y_label)\n",
    "        ax.set_title(f'{headline_var}', fontsize=40)\n",
    "\n",
    "        # Setting the formatter for scientific notation\n",
    "        formatter = mticker.ScalarFormatter(useMathText=True)\n",
    "        formatter.set_scientific(True)\n",
    "        formatter.set_powerlimits((-2,2))\n",
    "        ax.yaxis.set_major_formatter(formatter)\n",
    "\n",
    "        # Show legend if it's not a bar plot for sres or sdiv\n",
    "        if metric not in ['sres', 'sdiv']:\n",
    "            ax.legend()\n",
    "\n",
    "    # Adjust layout and show plot\n",
    "    plt.tight_layout()\n",
    "    plt.show();\n",
    "    f.savefig(f'../docs/time_{metric}.pdf', dpi=200, bbox_inches='tight');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0623d13e-3e54-4faf-9632-1712aa101238",
   "metadata": {},
   "source": [
    "### Ablation 2: Boundary Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97d9ace-a1c0-4b1d-8bb7-4a391428da8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluate metrics without and with BC \n",
    "metrics = ['rmse', 'acc', 'ssim']\n",
    "model_names = {'resnet_s2s': ['version_0', 'version_4'], 'unet_s2s': ['version_0', 'version_22']}\n",
    "labels = ['ResNet', 'UNet']\n",
    "\n",
    "all_data = []\n",
    "\n",
    "for metric_idx, metric in enumerate(metrics):\n",
    "    \n",
    "    # Iterate over each headline variable\n",
    "    for headline_idx, (headline_var, headline_unit) in enumerate(headline_vars.items()):\n",
    "\n",
    "        # Collect data for this headline variable\n",
    "        for model_idx, (model_name, versions) in enumerate(model_names.items()):\n",
    "            for version_idx, version in enumerate(versions):\n",
    "                df = pd.read_csv(Path(f'../logs/{model_name}/eval/{version}/{metric}_{model_name}.csv'))\n",
    "                last_value = df[headline_var].iloc[-1] # Get the last timestep\n",
    "\n",
    "                # Append data with additional detail\n",
    "                all_data.append({\n",
    "                    'Metric': metric,\n",
    "                    'Variable': headline_var,\n",
    "                    'Model': labels[model_idx],\n",
    "                    'Condition': (\"w/o BC\", \"with BC\")[version_idx],\n",
    "                    'Value': last_value\n",
    "                })\n",
    "\n",
    "# Convert to DataFrame\n",
    "all_data = pd.DataFrame(all_data)\n",
    "all_data = all_data.pivot_table(index=['Metric', 'Variable', 'Model'], columns='Condition',  values='Value', aggfunc='mean') \n",
    "all_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46dada9b-a292-4fbb-9e0b-f8866c8c7a72",
   "metadata": {},
   "source": [
    "### Ablation 3: ML Ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c07dc2-18df-4a96-ab98-2eb235791ef7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluate metrics across data-driven models\n",
    "# Case 3a: ensemble/deterministic ratio\n",
    "metrics = ['rmse', 'acc', 'bias', 'ssim', 'sdiv']\n",
    "linecolors = {'unet': '#1f77b4', 'resnet': '#ff7f0e'}\n",
    "model_names = {'unet': 'UNet (n=5)', 'resnet': 'ResNet (n=5)'}\n",
    "\n",
    "# Iterate over each metric\n",
    "for metric_idx, metric in enumerate(metrics):\n",
    "    f, axes = plt.subplots(1, len(headline_vars), figsize=(10 * len(headline_vars), 10))\n",
    "\n",
    "    for headline_idx, (headline_var, headline_unit) in enumerate(headline_vars.items()):\n",
    "        ax = axes[headline_idx] if len(headline_vars) > 1 else axes\n",
    "        data_to_plot = []\n",
    "\n",
    "        # Plot the ratio between control and ensemble models\n",
    "        for model_name, model_label in model_names.items():\n",
    "            control_df = pd.read_csv(Path(f'../logs/{model_name}_s2s/eval/version_0/{metric}_{model_name}_s2s.csv'))\n",
    "            ensemble_df = pd.read_csv(Path(f'../logs/{model_name}_ensemble_s2s/eval/{metric}_{model_name}_ensemble_s2s.csv'))\n",
    "            \n",
    "            control_y = control_df[headline_var].to_numpy()\n",
    "            ensemble_y = ensemble_df[headline_var].to_numpy()\n",
    "\n",
    "            if len(control_y) != len(ensemble_y):\n",
    "                raise ValueError(f\"Length mismatch between control and ensemble for {model_name}\")\n",
    "\n",
    "            # Calculate the ratio\n",
    "            ratio_y = ensemble_y / control_y\n",
    "\n",
    "            if metric in ['sres', 'sdiv']:\n",
    "                average_ratio_y = np.nanmean(ratio_y)\n",
    "                data_to_plot.append({'Model': model_label, 'Average': average_ratio_y})\n",
    "            else:\n",
    "                if np.nanmean(ratio_y) != 0.0:\n",
    "                    sns.lineplot(\n",
    "                        x=np.arange(1, len(ratio_y) + 1),\n",
    "                        y=ratio_y,\n",
    "                        label=f'{model_names[model_name]}',\n",
    "                        linewidth=5,\n",
    "                        linestyle='-',\n",
    "                        color=linecolors[model_name],\n",
    "                        ax=ax\n",
    "                    )\n",
    "                    \n",
    "\n",
    "        # Plot bar for metrics that require it\n",
    "        if metric in ['sres', 'sdiv']:\n",
    "            bar = sns.barplot(\n",
    "                x='Model',\n",
    "                y='Average',\n",
    "                data=pd.DataFrame(data_to_plot),\n",
    "                ax=ax,\n",
    "                palette=[linecolors[name.split()[0].lower()] for name in model_names.values()]\n",
    "            )\n",
    "            bar.set_xticklabels(bar.get_xticklabels(), rotation=30)\n",
    "\n",
    "        # Customize labels and titles based on the metric\n",
    "        x_label = '' if metric in ['sres', 'sdiv'] else 'Number of days ahead'\n",
    "        y_label = f'{metric.upper()} [ens/det]'\n",
    "        ax.set_xlabel(x_label)\n",
    "        ax.set_ylabel(y_label)\n",
    "        ax.set_title(f'{headline_var}', fontsize=40)\n",
    "\n",
    "        # Setting the formatter for scientific notation\n",
    "        formatter = mticker.ScalarFormatter(useMathText=True)\n",
    "        formatter.set_scientific(True)\n",
    "        formatter.set_powerlimits((-2, 2))\n",
    "        ax.yaxis.set_major_formatter(formatter)\n",
    "\n",
    "        # Show legend if it's not a bar plot for sres or sdiv\n",
    "        if metric not in ['sres', 'sdiv']:\n",
    "            ax.legend()\n",
    "\n",
    "    # Adjust layout and show plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    f.savefig(f'../docs/ml_ratio_{metric}.pdf', dpi=200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4715aaf-1294-4b95-9cd1-7bb25ba5df51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluate metrics across physics-based models maintained by different centers\n",
    "# Case 3b: probabilistic metrics\n",
    "metrics = ['crps', 'crpss', 'spread', 'ssr']\n",
    "linecolors = {'unet': '#1f77b4', 'resnet': '#ff7f0e'}\n",
    "model_names = {'unet': 'UNet (n=5)', 'resnet': 'ResNet (n=5)'}\n",
    "\n",
    "for metric_idx, metric in enumerate(metrics):\n",
    "    f, axes = plt.subplots(1, len(headline_vars), figsize=(10*len(headline_vars), 10))\n",
    "\n",
    "    for headline_idx, (headline_var, headline_unit) in enumerate(headline_vars.items()):\n",
    "        ax = axes[headline_idx] if len(headline_vars) > 1 else axes\n",
    "        data_to_plot = []\n",
    "\n",
    "        # Collect and plot data for this headline variable\n",
    "        for model_name, model_label in model_names.items():\n",
    "            \n",
    "            df = pd.read_csv(Path(f'../logs/{model_name}_ensemble_s2s/eval/{metric}_{model_name}_ensemble_s2s.csv'))\n",
    "            y = df[[headline_var]].to_numpy().squeeze()\n",
    "\n",
    "            if y.mean() != 0.0:  # Only plot if the mean is not zero\n",
    "                    \n",
    "                sns.lineplot(\n",
    "                    x=np.arange(1, df.shape[0]+1),\n",
    "                    y=y, \n",
    "                    label=model_label,\n",
    "                    linewidth=5,\n",
    "                    color=linecolors[model_name],\n",
    "                    ax=ax\n",
    "                )\n",
    "            \n",
    "\n",
    "        # Customize labels and titles based on the metric\n",
    "        x_label = '' if metric in ['sres', 'sdiv'] else 'Number of days ahead' \n",
    "        y_label = f'{metric.upper()}' if metric in ['crpss', 'ssr'] else f'{metric.upper()} [{headline_unit}]'\n",
    "        ax.set_xlabel(x_label)\n",
    "        ax.set_ylabel(y_label)\n",
    "        ax.set_title(f'{headline_var}', fontsize=40)\n",
    "\n",
    "        # Setting the formatter for scientific notation\n",
    "        formatter = mticker.ScalarFormatter(useMathText=True)\n",
    "        formatter.set_scientific(True)\n",
    "        formatter.set_powerlimits((-2,2))\n",
    "        ax.yaxis.set_major_formatter(formatter)\n",
    "        ax.legend()\n",
    "\n",
    "    # Adjust layout and show plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    f.savefig(f'../docs/ml_probs_{metric}.pdf', dpi=200, bbox_inches='tight');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38b5700-1ce6-48ab-be9e-150420bb8174",
   "metadata": {},
   "source": [
    "## Prediction visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111b1c13-c2a6-4aba-851d-8ca861ad2a2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#################### CHANGE THIS ####################\n",
    "date_idx = 0\n",
    "param = 't'\n",
    "level = 850\n",
    "model_name = 'resnet_s2s'\n",
    "\n",
    "plot_idx = [1, config.N_STEPS - 1]\n",
    "######################################################\n",
    "\n",
    "## Dataset\n",
    "input_dataset = dataset.S2SObsDataset(years=[2022], n_step=config.N_STEPS)\n",
    "output_dataset = dataset.S2SObsDataset(years=[2022], n_step=config.N_STEPS)\n",
    "\n",
    "\n",
    "## Load config filepath which consists of all the definition needed to fit/eval a model\n",
    "log_dir = Path('../logs') / model_name\n",
    "model_config_filepath = Path(f'../chaosbench/configs/{model_name}.yaml')\n",
    "\n",
    "with open(model_config_filepath, 'r') as config_filepath:\n",
    "    hyperparams = yaml.load(config_filepath, Loader=yaml.FullLoader)\n",
    "\n",
    "model_args = hyperparams['model_args']\n",
    "data_args = hyperparams['data_args']\n",
    "param_level_idx = utils.get_param_level_idx(param, level)\n",
    "\n",
    "## Checkpointing\n",
    "versions = ['version_0', 'version_1', 'version_2', 'version_3']\n",
    "\n",
    "for version in versions:\n",
    "    all_preds = list()\n",
    "    all_truth = list()\n",
    "    \n",
    "    S = 'S=1' if (('0' in version) or ('2' in version)) else 'S=5'\n",
    "    task = 'Task 1' if (('0' in version) or ('1' in version)) else 'Task 2'\n",
    "    \n",
    "    ckpt_filepath = log_dir / f'lightning_logs/{version}/checkpoints/'\n",
    "    ckpt_filepath = list(ckpt_filepath.glob('*.ckpt'))[0]\n",
    "    baseline = model.S2SBenchmarkModel(model_args=model_args, data_args=data_args)\n",
    "    baseline = baseline.load_from_checkpoint(ckpt_filepath)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        timestamp, input_x, input_y = input_dataset[date_idx]\n",
    "        _, output_x, output_y = output_dataset[date_idx]\n",
    "\n",
    "        curr_x = input_x.unsqueeze(0).to(device)\n",
    "\n",
    "        for step_idx in range(config.N_STEPS - 1):\n",
    "            preds = baseline(curr_x)\n",
    "            curr_y = output_y.unsqueeze(0)[:, step_idx + 1]\n",
    "\n",
    "            if step_idx + 1 in plot_idx:\n",
    "                all_preds.append(preds[0][param_level_idx].detach().cpu().numpy())\n",
    "                all_truth.append(curr_y[0][param_level_idx].detach().cpu().numpy())\n",
    "\n",
    "            curr_x = preds \n",
    "            \n",
    "    # Plotting\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_truth = np.array(all_truth)\n",
    "\n",
    "    f, ax = plt.subplots(3, len(plot_idx), figsize=(8, 3 * len(plot_idx)))\n",
    "\n",
    "    for time_idx in range(len(plot_idx)):\n",
    "\n",
    "        im0 = ax[0, time_idx].imshow(all_truth[time_idx], cmap='RdBu_r', vmin=-2, vmax=2)\n",
    "        # ax[0, time_idx].set_title(f'Truth\\n(step={plot_idx[time_idx]})')\n",
    "        ax[0, time_idx].axis('off')\n",
    "        cbar0 = f.colorbar(im0, ax=ax[0, time_idx], shrink=0.8)\n",
    "\n",
    "        im1 = ax[1, time_idx].imshow(all_preds[time_idx], cmap='RdBu_r', vmin=-2, vmax=2)\n",
    "        # ax[1, time_idx].set_title(f'Prediction\\n(step={plot_idx[time_idx]})')\n",
    "        ax[1, time_idx].axis('off')\n",
    "        cbar1 = f.colorbar(im1, ax=ax[1, time_idx], shrink=0.8)\n",
    "\n",
    "        im2 = ax[2, time_idx].imshow(all_preds[time_idx] - all_truth[time_idx], cmap='RdBu_r', vmin=-1, vmax=1)\n",
    "        # ax[2, time_idx].set_title(f'Residual\\n(step={plot_idx[time_idx]})')\n",
    "        ax[2, time_idx].axis('off')\n",
    "        cbar2 = f.colorbar(im2, ax=ax[2, time_idx], shrink=0.8)\n",
    "\n",
    "    # Adding titles for each row\n",
    "    titles = [r'$Truth$', r'$Prediction$', r'$Residual$']\n",
    "    for idx, title in enumerate(titles):\n",
    "        f.text(-0.01, 0.82 - idx*0.32, title, va='center', ha='left', fontsize=12, rotation=90)\n",
    "\n",
    "    ax[0,0].set_title(f'{task} ({S})\\n norm-{param}{level}\\n t = 1', fontsize=12)\n",
    "    ax[0,1].set_title(f'{task} ({S})\\n norm-{param}{level}\\n t = 44', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    # f.savefig(f'../docs/preds_{model_name}_{param}{level}_{S}_{task}.pdf', dpi=200, bbox_inches='tight');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea43653-b4f0-48a3-ad9c-8098fd19e999",
   "metadata": {},
   "source": [
    "## Power spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4605cbb-4747-4439-9eae-82b508ace438",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#################### CHANGE THIS ####################\n",
    "date_idx = 0\n",
    "n_steps = [0, 43]\n",
    "model_type = 'unet'\n",
    "task = 1\n",
    "######################################################\n",
    "\n",
    "param_levels = [['t', 850], ['z', 500], ['q', 700]]\n",
    "\n",
    "if task == 1:\n",
    "    model_list = [\n",
    "        dict({f'Task_{task}/S=1': f'{model_type}_s2s/version_0', \n",
    "              f'Task_{task}/S=5': f'{model_type}_s2s/version_1'}), # task 1\n",
    "    ]\n",
    "    \n",
    "else:\n",
    "    model_list = [\n",
    "        dict({f'Task_{task}/S=1': f'{model_type}_s2s/version_2', \n",
    "              f'Task_{task}/S=5': f'{model_type}_s2s/version_3'}), # task 2\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7e1b5b-9cdc-45fe-a788-df9fc4433e4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot individual spectra at t=1 and t=44\n",
    "all_Sk = dict()\n",
    "\n",
    "## Initialize dataset\n",
    "input_dataset = dataset.S2SObsDataset(years=[2022], n_step=config.N_STEPS)\n",
    "output_dataset = dataset.S2SObsDataset(years=[2022], n_step=config.N_STEPS)\n",
    "\n",
    "# Compute power spectrum for each model and its configuration\n",
    "f, ax = plt.subplots(len(n_steps), len(param_levels), figsize=(10*len(param_levels), 10*len(n_steps)))\n",
    "\n",
    "\n",
    "for i, param_level in enumerate(param_levels):\n",
    "    param = param_level[0]\n",
    "    level = param_level[1]\n",
    "    param_level_idx = utils.get_param_level_idx(param, level)\n",
    "\n",
    "    for model_item in model_list:\n",
    "\n",
    "        for _, (model_spec, model_name) in enumerate(model_item.items()):\n",
    "            print(f'Processing {model_spec}')\n",
    "\n",
    "            all_preds, all_truth = list(), list()\n",
    "\n",
    "            model_basename, model_version = model_name.split('/')\n",
    "\n",
    "            log_dir = Path('../logs') / model_basename\n",
    "            model_config_filepath = Path(f'../chaosbench/configs/{model_basename}.yaml')\n",
    "\n",
    "            with open(model_config_filepath, 'r') as config_filepath:\n",
    "                hyperparams = yaml.load(config_filepath, Loader=yaml.FullLoader)\n",
    "\n",
    "            model_args = hyperparams['model_args']\n",
    "            data_args = hyperparams['data_args']\n",
    "\n",
    "            # Load checkpoints\n",
    "            ckpt_filepath = log_dir / f'lightning_logs/{model_version}/checkpoints/'\n",
    "            ckpt_filepath = list(ckpt_filepath.glob('*.ckpt'))[0]\n",
    "            baseline = model.S2SBenchmarkModel(model_args=model_args, data_args=data_args)\n",
    "            baseline = baseline.load_from_checkpoint(ckpt_filepath)\n",
    "\n",
    "            with torch.no_grad():\n",
    "\n",
    "                timestamp, input_x, input_y = input_dataset[date_idx]\n",
    "                _, output_x, output_y = output_dataset[date_idx]\n",
    "\n",
    "                curr_x = input_x.unsqueeze(0).to(device)\n",
    "\n",
    "                for step_idx in range(config.N_STEPS - 1):\n",
    "                    preds = baseline(curr_x)\n",
    "                    curr_y = output_y.unsqueeze(0)[:, step_idx + 1]\n",
    "\n",
    "                    all_preds.append(\n",
    "                        preds[0][param_level_idx].detach().cpu().numpy()\n",
    "                    )\n",
    "\n",
    "                    all_truth.append(\n",
    "                        curr_y[0][param_level_idx].detach().cpu().numpy()\n",
    "                    )\n",
    "\n",
    "                    curr_x = preds \n",
    "\n",
    "            all_preds, all_truth = np.array(all_preds), np.array(all_truth)\n",
    "\n",
    "\n",
    "            # Plot power spectrum\n",
    "            curr_pred_Sk, curr_truth_Sk = list(), list()\n",
    "\n",
    "            for step_idx in range(all_preds.shape[0]):\n",
    "                pred_t, truth_t = all_preds[step_idx], all_truth[step_idx]\n",
    "                pred_power_t, truth_power_t = np.fft.fft2(pred_t), np.fft.fft2(truth_t)\n",
    "                pred_power_t, truth_power_t = np.abs(pred_power_t)**2, np.abs(truth_power_t)**2\n",
    "\n",
    "                ny, nx = pred_t.shape\n",
    "                kx = np.fft.fftfreq(nx) * nx\n",
    "                ky = np.fft.fftfreq(ny) * ny\n",
    "\n",
    "                kx, ky = np.meshgrid(kx, ky)\n",
    "                k = np.sqrt(kx**2 + ky**2)\n",
    "\n",
    "                k_bins = np.arange(0.5, np.max(k), 1)\n",
    "                k_bin_centers = 0.5 * (k_bins[:-1] + k_bins[1:])\n",
    "                pred_Sk = np.histogram(k, bins=k_bins, weights=pred_power_t)[0] / np.histogram(k, bins=k_bins)[0]\n",
    "                truth_Sk = np.histogram(k, bins=k_bins, weights=truth_power_t)[0] / np.histogram(k, bins=k_bins)[0]\n",
    "\n",
    "                curr_pred_Sk.append(pred_Sk)\n",
    "                curr_truth_Sk.append(truth_Sk)\n",
    "\n",
    "                if step_idx in n_steps:\n",
    "                    step_num = n_steps.index(step_idx)\n",
    "                    ax[step_num, i].set_title(f'{param}-{level}', fontsize=24)\n",
    "                    ax[step_num, i].loglog(pred_Sk, label=f'{model_spec}', linewidth=3)\n",
    "                    ax[step_num, i].set_xlabel('Wavenumber, k')\n",
    "                    ax[step_num, i].set_ylabel(f'Power, S(k); {step_idx + 1}-day ahead')\n",
    "                    ax[step_num, i].set_ylim([10**0, 10**7])\n",
    "                    ax[step_num, i].legend()\n",
    "\n",
    "            all_Sk[f'{model_spec}:{param}-{level}'] = np.array(curr_pred_Sk)\n",
    "            all_Sk['truth'] = np.array(curr_truth_Sk)\n",
    "\n",
    "plt.show()\n",
    "f.savefig(f'../docs/specdiv_{model_type}_Task {task}.pdf', dpi=200, bbox_inches='tight');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c8759b-6112-4faa-9540-da3a330e4260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot full power spectra\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "\n",
    "def set_log_ticks_10_power(axis, num_ticks=5):\n",
    "    lims = axis.get_data_interval()\n",
    "    \n",
    "    ticks = np.linspace(lims[0], lims[1], num=num_ticks)\n",
    "    axis.set_ticks(ticks)\n",
    "    axis.set_ticklabels([f'$10^{{{int(tick)}}}$' for tick in ticks])\n",
    "\n",
    "\n",
    "eps = 1e-50 # to void log(0)\n",
    "task_s = list(model_list[0].keys())\n",
    "f = plt.figure(figsize=(16, 10))\n",
    "subplot_idx = 1\n",
    "\n",
    "for task_id, task in enumerate(task_s):\n",
    "    task_num, step_size = task.split('/')\n",
    "    \n",
    "    for param_id, param_level in enumerate(param_levels):\n",
    "        \n",
    "        curr_Sk = all_Sk[f'{task}:{param_level[0]}-{param_level[1]}']\n",
    "    \n",
    "        # Plot the 3D contour plot\n",
    "        ax = f.add_subplot(len(task_s), len(param_levels), subplot_idx, projection='3d')\n",
    "        Wavenumber, Timestep = np.meshgrid(np.arange(1, curr_Sk.shape[1] + 1), np.arange(1, curr_Sk.shape[0] + 1))\n",
    "        contour = ax.contour3D(np.log10(Wavenumber + eps), Timestep, np.log10(curr_Sk + eps), 100, cmap='inferno_r')\n",
    "\n",
    "        ax.set_xlabel('Wavenumber, k')\n",
    "        ax.set_ylabel('Number of days ahead')\n",
    "        ax.set_zlabel(r'Power, S(k)', labelpad=0.1)\n",
    "\n",
    "        set_log_ticks_10_power(ax.xaxis)\n",
    "        set_log_ticks_10_power(ax.zaxis)\n",
    "        \n",
    "        ax.set_title(f'{task_num} ({step_size})\\n {param_level[0]}{param_level[1]}', fontsize=12)\n",
    "        subplot_idx += 1\n",
    "\n",
    "plt.show()\n",
    "f.savefig(f'../docs/3d_{model_type}_{task_num}.pdf', dpi=200, bbox_inches='tight');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1d6bd4-22ec-4cf3-b117-3bbc6be59704",
   "metadata": {},
   "source": [
    "## Effects of temporal information\n",
    "For autoregressive approach..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae503224-9b16-48a8-a085-4f068b279006",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot metrics over time, across tasks\n",
    "\n",
    "model_list = [\n",
    "    dict({'S=1': 'unet_s2s/version_0', 'S=5': 'unet_s2s/version_1'}), # task 1\n",
    "    # dict({'Task_2/S=1': 'unet_s2s/version_2', 'Task_2/S=5': 'unet_s2s/version_3'}), # task 2\n",
    "]\n",
    "\n",
    "metrics = ['rmse', 'acc', 'ssim', 'sdiv']\n",
    "headline_vars = dict({'t-850': 'K', 'z-500': 'gpm', 'q-700': r'$10^{-3}kg kg^{-1}$'})\n",
    "\n",
    "for metric in metrics:\n",
    "    \n",
    "    f, ax = plt.subplots(1, len(headline_vars), figsize=(10*len(headline_vars), 8))\n",
    "    \n",
    "    for model_item in model_list:\n",
    "    \n",
    "        for model_idx, (model_spec, model_name) in enumerate(model_item.items()):\n",
    "        \n",
    "            model_basename, version_num = model_name.split('/')\n",
    "            df = pd.read_csv(Path(f'../logs/{model_basename}/eval/{version_num}/{metric}_{model_basename}.csv'))\n",
    "\n",
    "            for headline_idx, (headline_var, headline_unit) in enumerate(headline_vars.items()):\n",
    "                \n",
    "                if 'q' in headline_var and metric == 'rmse':\n",
    "                    y = df[[headline_var]].to_numpy().squeeze() * 1000 \n",
    "                \n",
    "                else:\n",
    "                    y = df[[headline_var]].to_numpy().squeeze()\n",
    "\n",
    "                sns.lineplot(\n",
    "                    x=np.arange(1, df.shape[0]+1),\n",
    "                    y=y, \n",
    "                    label=f'{model_spec}',\n",
    "                    linewidth=5,\n",
    "                    ax=ax[headline_idx]\n",
    "                )\n",
    "\n",
    "                ## Labeling\n",
    "                ax[headline_idx].set_xlim([0,45])\n",
    "                ax[headline_idx].set_xlabel('Number of days ahead')\n",
    "                \n",
    "                if metric == 'rmse':\n",
    "                    ax[headline_idx].set_ylabel(f'{metric.upper()} [{headline_unit}]')\n",
    "                    \n",
    "                elif metric == 'sdiv':\n",
    "                    ax[headline_idx].set_ylabel(f'{metric.upper()}')\n",
    "                    \n",
    "                else:\n",
    "                    ax[headline_idx].set_ylabel(f'{metric.upper()}')\n",
    "                    ax[headline_idx].set_ylim([0,1])\n",
    "                    \n",
    "                ax[headline_idx].set_title(f'{headline_var}', fontsize=40)\n",
    "                \n",
    "    f.savefig(f'../docs/autoreg_{metric}_task1.pdf', dpi=200, bbox_inches='tight');\n",
    "            \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0b3711-7f17-4450-ae40-b18f826e61a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bench",
   "language": "python",
   "name": "bench"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
